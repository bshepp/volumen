{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vesuvius Challenge - Surface Detection\n",
        "## Submission Notebook\n",
        "\n",
        "Periodicity-aware 3D surface segmentation using engineered differential-geometric features and topology-aware 3D U-Net."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tifffile\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA available: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths - adjust these for Kaggle\n",
        "DATA_DIR = '/kaggle/input/vesuvius-challenge-surface-detection'\n",
        "MODEL_DIR = '/kaggle/input/vesuvius-model-weights'  # Your uploaded model weights dataset\n",
        "MODEL_PATH = os.path.join(MODEL_DIR, 'best_model.pth')\n",
        "\n",
        "# Inference settings\n",
        "PATCH_SIZE = 128\n",
        "STRIDE = 64\n",
        "USE_TTA = True\n",
        "USE_POSTPROCESS = True\n",
        "\n",
        "# Model architecture (must match training)\n",
        "IN_CHANNELS = 6\n",
        "NUM_CLASSES = 3\n",
        "BASE_FILTERS = 32\n",
        "DEPTH = 4\n",
        "\n",
        "# Post-processing\n",
        "MIN_COMPONENT_SIZE = 500\n",
        "BRIDGE_THRESHOLD = 3\n",
        "MIN_SHEET_SPACING = 10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "use_amp = device.type == 'cuda'\n",
        "print(f'Device: {device}, AMP: {use_amp}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_features(volume, normalize=True):\n",
        "    \"\"\"Compute 6-channel feature volume from raw CT.\"\"\"\n",
        "    vol = volume.astype(np.float32)\n",
        "    raw_norm = vol / 255.0\n",
        "    smooth = gaussian_filter(vol, sigma=1.0)\n",
        "    log_s1 = gaussian_filter(vol, sigma=1.0) - gaussian_filter(vol, sigma=1.5)\n",
        "    log_s2 = gaussian_filter(vol, sigma=2.0) - gaussian_filter(vol, sigma=3.0)\n",
        "    gz = np.gradient(smooth, axis=0)\n",
        "    gy = np.gradient(smooth, axis=1)\n",
        "    gx = np.gradient(smooth, axis=2)\n",
        "    hzz = np.gradient(gz, axis=0)\n",
        "    hyy = np.gradient(gy, axis=1)\n",
        "    hxx = np.gradient(gx, axis=2)\n",
        "    hessian_trace = hzz + hyy + hxx\n",
        "    grad_mag = np.sqrt(gz**2 + gy**2 + gx**2)\n",
        "    abs_gy = np.abs(gy)\n",
        "    abs_gx = np.abs(gx)\n",
        "    gy_gx_ratio = np.clip(abs_gy / (abs_gx + 1e-3), 0.0, 20.0)\n",
        "    features = np.stack([raw_norm, log_s1, log_s2, hessian_trace, grad_mag, gy_gx_ratio], axis=0).astype(np.float32)\n",
        "    if normalize:\n",
        "        for c in range(features.shape[0]):\n",
        "            mu = features[c].mean()\n",
        "            std = features[c].std()\n",
        "            if std > 1e-8:\n",
        "                features[c] = (features[c] - mu) / std\n",
        "            else:\n",
        "                features[c] = features[c] - mu\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock3D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv3d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.InstanceNorm3d(out_ch, affine=True),\n",
        "            nn.LeakyReLU(0.01, inplace=True),\n",
        "            nn.Conv3d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.InstanceNorm3d(out_ch, affine=True),\n",
        "            nn.LeakyReLU(0.01, inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.down = nn.Sequential(\n",
        "            nn.Conv3d(in_ch, in_ch, 2, stride=2, bias=False),\n",
        "            nn.InstanceNorm3d(in_ch, affine=True),\n",
        "            nn.LeakyReLU(0.01, inplace=True),\n",
        "        )\n",
        "        self.conv = ConvBlock3D(in_ch, out_ch)\n",
        "    def forward(self, x):\n",
        "        return self.conv(self.down(x))\n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "    def __init__(self, in_ch, skip_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose3d(in_ch, in_ch, 2, stride=2, bias=False)\n",
        "        self.conv = ConvBlock3D(in_ch + skip_ch, out_ch)\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        if x.shape != skip.shape:\n",
        "            dz = skip.shape[2] - x.shape[2]\n",
        "            dy = skip.shape[3] - x.shape[3]\n",
        "            dx = skip.shape[4] - x.shape[4]\n",
        "            x = F.pad(x, [dx//2, dx-dx//2, dy//2, dy-dy//2, dz//2, dz-dz//2])\n",
        "        return self.conv(torch.cat([x, skip], dim=1))\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, in_channels=6, num_classes=3, base_filters=32, depth=4):\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        filters = [base_filters * (2**i) for i in range(depth)]\n",
        "        self.init_conv = ConvBlock3D(in_channels, filters[0])\n",
        "        self.encoders = nn.ModuleList([DownBlock(filters[i-1], filters[i]) for i in range(1, depth)])\n",
        "        self.bottleneck = DownBlock(filters[-1], filters[-1]*2)\n",
        "        self.decoders = nn.ModuleList()\n",
        "        dec_in = filters[-1]*2\n",
        "        for i in range(depth-1, -1, -1):\n",
        "            self.decoders.append(UpBlock(dec_in, filters[i], filters[i]))\n",
        "            dec_in = filters[i]\n",
        "        self.final_conv = nn.Conv3d(filters[0], num_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skips = []\n",
        "        x = self.init_conv(x)\n",
        "        skips.append(x)\n",
        "        for enc in self.encoders:\n",
        "            x = enc(x)\n",
        "            skips.append(x)\n",
        "        x = self.bottleneck(x)\n",
        "        for i, dec in enumerate(self.decoders):\n",
        "            x = dec(x, skips[-(i+1)])\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Post-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.ndimage import (\n",
        "    binary_dilation, binary_erosion, generate_binary_structure,\n",
        "    label as ndimage_label, distance_transform_edt\n",
        ")\n",
        "from scipy import ndimage\n",
        "\n",
        "def get_struct(conn=26):\n",
        "    return generate_binary_structure(3, {6:1, 18:2, 26:3}[conn])\n",
        "\n",
        "def remove_small_components(mask, min_size=500, conn=26):\n",
        "    labeled, n = ndimage_label(mask, structure=get_struct(conn))\n",
        "    if n == 0: return mask\n",
        "    sizes = ndimage.sum(mask, labeled, range(1, n+1))\n",
        "    keep = np.zeros_like(mask)\n",
        "    for i, s in enumerate(sizes, 1):\n",
        "        if s >= min_size: keep[labeled == i] = 1\n",
        "    return keep.astype(np.uint8)\n",
        "\n",
        "def remove_bridges(mask, thickness=3, conn=26):\n",
        "    if mask.sum() == 0: return mask\n",
        "    struct = get_struct(conn)\n",
        "    eroded = binary_erosion(mask, structure=struct, iterations=thickness).astype(np.uint8)\n",
        "    if eroded.sum() == 0: return mask\n",
        "    labeled, n = ndimage_label(eroded, structure=struct)\n",
        "    if n <= 1: return mask\n",
        "    territories = np.zeros(mask.shape, dtype=np.int32)\n",
        "    conflict = np.zeros(mask.shape, dtype=bool)\n",
        "    for cid in range(1, n+1):\n",
        "        dilated = binary_dilation((labeled==cid).astype(np.uint8), structure=struct, iterations=thickness+1)\n",
        "        dilated = dilated & mask.astype(bool)\n",
        "        conflict |= ((territories > 0) & dilated)\n",
        "        territories[dilated & (territories == 0)] = cid\n",
        "    result = mask.copy()\n",
        "    result[conflict] = 0\n",
        "    return remove_small_components(result, min_size=100, conn=conn)\n",
        "\n",
        "def fill_small_holes(mask, max_size=200):\n",
        "    inv = 1 - mask.astype(np.uint8)\n",
        "    labeled, n = ndimage_label(inv, structure=generate_binary_structure(3, 1))\n",
        "    result = mask.copy()\n",
        "    for i in range(1, n+1):\n",
        "        hole = labeled == i\n",
        "        if hole.sum() > max_size: continue\n",
        "        touches = hole[0].any() or hole[-1].any() or hole[:,0].any() or hole[:,-1].any() or hole[:,:,0].any() or hole[:,:,-1].any()\n",
        "        if not touches: result[hole] = 1\n",
        "    return result.astype(np.uint8)\n",
        "\n",
        "def postprocess(pred, min_comp=500, bridge_t=3, min_spacing=10):\n",
        "    pred = pred.astype(np.uint8)\n",
        "    pred = remove_small_components(pred, min_comp)\n",
        "    pred = remove_bridges(pred, bridge_t)\n",
        "    pred = fill_small_holes(pred)\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sliding Window Inference + TTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sliding_window(model, features, patch_size=128, stride=64, device='cpu', use_amp=True, num_classes=3):\n",
        "    model.eval()\n",
        "    C, Z, Y, X = features.shape\n",
        "    pad_z, pad_y, pad_x = max(0, patch_size-Z), max(0, patch_size-Y), max(0, patch_size-X)\n",
        "    if pad_z > 0 or pad_y > 0 or pad_x > 0:\n",
        "        features = np.pad(features, ((0,0),(0,pad_z),(0,pad_y),(0,pad_x)), mode='reflect')\n",
        "    _, Zp, Yp, Xp = features.shape\n",
        "    prob_sum = np.zeros((num_classes, Zp, Yp, Xp), dtype=np.float32)\n",
        "    count = np.zeros((Zp, Yp, Xp), dtype=np.float32)\n",
        "    zs = list(range(0, Zp-patch_size+1, stride))\n",
        "    ys = list(range(0, Yp-patch_size+1, stride))\n",
        "    xs = list(range(0, Xp-patch_size+1, stride))\n",
        "    if zs[-1]+patch_size < Zp: zs.append(Zp-patch_size)\n",
        "    if ys[-1]+patch_size < Yp: ys.append(Yp-patch_size)\n",
        "    if xs[-1]+patch_size < Xp: xs.append(Xp-patch_size)\n",
        "    total = len(zs)*len(ys)*len(xs)\n",
        "    print(f'  {total} patches ({len(zs)}x{len(ys)}x{len(xs)})')\n",
        "    with torch.no_grad():\n",
        "        idx = 0\n",
        "        for z0 in zs:\n",
        "            for y0 in ys:\n",
        "                for x0 in xs:\n",
        "                    p = features[:, z0:z0+patch_size, y0:y0+patch_size, x0:x0+patch_size]\n",
        "                    pt = torch.from_numpy(p[np.newaxis]).float().to(device)\n",
        "                    if use_amp and device.type == 'cuda':\n",
        "                        with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "                            logits = model(pt)\n",
        "                    else:\n",
        "                        logits = model(pt)\n",
        "                    probs = F.softmax(logits, dim=1)[0].cpu().float().numpy()\n",
        "                    prob_sum[:, z0:z0+patch_size, y0:y0+patch_size, x0:x0+patch_size] += probs\n",
        "                    count[z0:z0+patch_size, y0:y0+patch_size, x0:x0+patch_size] += 1.0\n",
        "                    idx += 1\n",
        "    count = np.maximum(count, 1.0)\n",
        "    return (prob_sum / count[np.newaxis])[:, :Z, :Y, :X]\n",
        "\n",
        "def run_tta(model, features, patch_size=128, stride=64, device='cpu', use_amp=True):\n",
        "    C, Z, Y, X = features.shape\n",
        "    prob_sum = np.zeros((NUM_CLASSES, Z, Y, X), dtype=np.float32)\n",
        "    for i, (fz, fy, fx) in enumerate([(a,b,c) for a in [0,1] for b in [0,1] for c in [0,1]]):\n",
        "        print(f'TTA {i+1}/8: flip z={fz} y={fy} x={fx}')\n",
        "        feat = features.copy()\n",
        "        if fz: feat = np.flip(feat, 1)\n",
        "        if fy: feat = np.flip(feat, 2)\n",
        "        if fx: feat = np.flip(feat, 3)\n",
        "        feat = np.ascontiguousarray(feat)\n",
        "        probs = sliding_window(model, feat, patch_size, stride, device, use_amp, NUM_CLASSES)\n",
        "        if fx: probs = np.flip(probs, 3)\n",
        "        if fy: probs = np.flip(probs, 2)\n",
        "        if fz: probs = np.flip(probs, 1)\n",
        "        prob_sum += np.ascontiguousarray(probs)\n",
        "    return prob_sum / 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_start = time.time()\n",
        "\n",
        "# Load model\n",
        "print('Loading model...')\n",
        "model = UNet3D(IN_CHANNELS, NUM_CLASSES, BASE_FILTERS, DEPTH)\n",
        "ckpt = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "if 'model_state_dict' in ckpt:\n",
        "    model.load_state_dict(ckpt['model_state_dict'])\n",
        "else:\n",
        "    model.load_state_dict(ckpt)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(f'Model loaded: {sum(p.numel() for p in model.parameters()):,} params')\n",
        "\n",
        "# Read test data\n",
        "import csv\n",
        "with open(os.path.join(DATA_DIR, 'test.csv')) as f:\n",
        "    test_ids = [row['id'] for row in csv.DictReader(f)]\n",
        "print(f'Test IDs: {test_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process each test volume\n",
        "predictions = {}\n",
        "for test_id in test_ids:\n",
        "    print(f'\\n=== Processing {test_id} ===')\n",
        "    \n",
        "    # Load volume\n",
        "    vol_path = os.path.join(DATA_DIR, 'test_images', f'{test_id}.tif')\n",
        "    volume = tifffile.imread(vol_path)\n",
        "    print(f'Volume: {volume.shape}, dtype={volume.dtype}')\n",
        "    \n",
        "    # Compute features\n",
        "    print('Computing features...')\n",
        "    t0 = time.time()\n",
        "    features = compute_features(volume, normalize=True)\n",
        "    print(f'Features computed in {time.time()-t0:.1f}s, shape={features.shape}')\n",
        "    \n",
        "    # Inference\n",
        "    if USE_TTA:\n",
        "        print('Running TTA inference...')\n",
        "        probs = run_tta(model, features, PATCH_SIZE, STRIDE, device, use_amp)\n",
        "    else:\n",
        "        print('Running inference...')\n",
        "        probs = sliding_window(model, features, PATCH_SIZE, STRIDE, device, use_amp, NUM_CLASSES)\n",
        "    \n",
        "    # Extract surface prediction\n",
        "    pred = (probs.argmax(axis=0) == 1).astype(np.uint8)\n",
        "    print(f'Raw prediction: {pred.sum()} surface voxels ({pred.sum()/pred.size*100:.1f}%)')\n",
        "    \n",
        "    # Post-process\n",
        "    if USE_POSTPROCESS:\n",
        "        print('Post-processing...')\n",
        "        pred = postprocess(pred, MIN_COMPONENT_SIZE, BRIDGE_THRESHOLD, MIN_SHEET_SPACING)\n",
        "        print(f'After post-processing: {pred.sum()} voxels ({pred.sum()/pred.size*100:.1f}%)')\n",
        "    \n",
        "    predictions[test_id] = pred\n",
        "\n",
        "print(f'\\nTotal inference time: {time.time()-t_start:.1f}s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save predictions as .tif files and create submission.zip\n",
        "os.makedirs('/kaggle/working/submission_files', exist_ok=True)\n",
        "\n",
        "for test_id, pred in predictions.items():\n",
        "    tif_path = f'/kaggle/working/submission_files/{test_id}.tif'\n",
        "    tifffile.imwrite(tif_path, pred)\n",
        "    print(f'Saved {tif_path}: shape={pred.shape}, dtype={pred.dtype}')\n",
        "\n",
        "# Create zip\n",
        "with zipfile.ZipFile('/kaggle/working/submission.zip', 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "    for test_id in predictions:\n",
        "        tif_path = f'/kaggle/working/submission_files/{test_id}.tif'\n",
        "        zf.write(tif_path, f'{test_id}.tif')\n",
        "\n",
        "print(f'\\nSubmission saved to /kaggle/working/submission.zip')\n",
        "print(f'Total time: {time.time()-t_start:.1f}s')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
